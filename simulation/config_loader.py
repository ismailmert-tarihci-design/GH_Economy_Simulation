"""
Configuration loader for the Bluestar Economy Simulator.

Loads default configuration from JSON files in data/defaults/
and returns a SimConfig object.
"""

import json
from pathlib import Path
from typing import Any

from simulation.models import (
    SimConfig,
    PackConfig,
    UpgradeTable,
    DuplicateRange,
    CoinPerDuplicate,
    ProgressionMapping,
    UserProfile,
    CardCategory,
)


def _get_defaults_dir() -> Path:
    """Get the path to the defaults directory."""
    # Get the directory of the current file
    current_dir = Path(__file__).parent.parent
    defaults_dir = current_dir / "data" / "defaults"
    return defaults_dir


def load_defaults() -> SimConfig:
    """
    Load default configuration from JSON files.

    Returns:
        SimConfig: Configuration object with all default values loaded.

    Raises:
        FileNotFoundError: If any required JSON file is missing.
        ValueError: If JSON structure doesn't match expected schema.
    """
    defaults_dir = _get_defaults_dir()

    # Load pack configs
    with open(defaults_dir / "pack_configs.json") as f:
        pack_data = json.load(f)
    packs = [PackConfig(**pack) for pack in pack_data["packs"]]

    # Load upgrade tables
    with open(defaults_dir / "upgrade_tables.json") as f:
        upgrade_data = json.load(f)
    upgrade_tables = {
        CardCategory(key): UpgradeTable(**value) for key, value in upgrade_data.items()
    }

    # Load duplicate ranges
    with open(defaults_dir / "duplicate_ranges.json") as f:
        duplicate_data = json.load(f)
    duplicate_ranges = {
        CardCategory(key): DuplicateRange(**value)
        for key, value in duplicate_data.items()
    }

    # Load coin per duplicate
    with open(defaults_dir / "coin_per_duplicate.json") as f:
        coin_data = json.load(f)
    coin_per_duplicate = {
        CardCategory(key): CoinPerDuplicate(**value) for key, value in coin_data.items()
    }

    # Load progression mapping
    with open(defaults_dir / "progression_mapping.json") as f:
        progression_data = json.load(f)
    # Convert the shared_to_unique dict to lists format expected by ProgressionMapping
    shared_to_unique = progression_data.get("shared_to_unique", {})
    shared_levels = sorted([int(k) for k in shared_to_unique.keys()])
    unique_levels = [shared_to_unique[str(k)] for k in shared_levels]
    progression_mapping = ProgressionMapping(
        shared_levels=shared_levels, unique_levels=unique_levels
    )

    # Load unique unlock schedule
    with open(defaults_dir / "unique_unlock_schedule.json") as f:
        schedule_data = json.load(f)
    # Convert string keys to integers
    unique_unlock_schedule = {int(k): v for k, v in schedule_data.items()}

    # Load daily pack schedule
    with open(defaults_dir / "daily_pack_schedule.json") as f:
        schedule_data = json.load(f)

    # Create SimConfig
    config = SimConfig(
        packs=packs,
        upgrade_tables=upgrade_tables,
        duplicate_ranges=duplicate_ranges,
        coin_per_duplicate=coin_per_duplicate,
        progression_mapping=progression_mapping,
        unique_unlock_schedule=unique_unlock_schedule,
        daily_pack_schedule=schedule_data,
        num_days=100,
    )

    return config


def save_defaults(config: "SimConfig") -> None:
    """
    Save the current SimConfig as the new default configuration.

    Writes each config section back to its corresponding JSON file
    in data/defaults/. Creates timestamped backups before overwriting.

    Args:
        config: SimConfig object to persist as defaults.
    """
    import shutil
    from datetime import datetime

    defaults_dir = _get_defaults_dir()
    backup_dir = defaults_dir / "backups"
    backup_dir.mkdir(parents=True, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    def _backup_and_write(filename: str, data: Any) -> None:
        path = defaults_dir / filename
        if path.exists():
            shutil.copy2(path, backup_dir / f"{path.stem}_{timestamp}{path.suffix}")
        with open(path, "w") as f:
            json.dump(data, f, indent=2)

    # Pack configs
    pack_data = {"packs": [p.model_dump() for p in config.packs]}
    _backup_and_write("pack_configs.json", pack_data)

    # Upgrade tables
    upgrade_data = {
        cat.value: table.model_dump() for cat, table in config.upgrade_tables.items()
    }
    _backup_and_write("upgrade_tables.json", upgrade_data)

    # Duplicate ranges
    dup_data = {
        cat.value: dr.model_dump() for cat, dr in config.duplicate_ranges.items()
    }
    _backup_and_write("duplicate_ranges.json", dup_data)

    # Coin per duplicate
    coin_data = {
        cat.value: cpd.model_dump() for cat, cpd in config.coin_per_duplicate.items()
    }
    _backup_and_write("coin_per_duplicate.json", coin_data)

    # Progression mapping
    shared_to_unique = {
        str(s): u
        for s, u in zip(
            config.progression_mapping.shared_levels,
            config.progression_mapping.unique_levels,
        )
    }
    _backup_and_write(
        "progression_mapping.json", {"shared_to_unique": shared_to_unique}
    )

    # Unique unlock schedule
    schedule_data = {str(k): v for k, v in config.unique_unlock_schedule.items()}
    _backup_and_write("unique_unlock_schedule.json", schedule_data)

    # Daily pack schedule
    _backup_and_write("daily_pack_schedule.json", config.daily_pack_schedule)


def _get_profiles_dir() -> Path:
    current_dir = Path(__file__).parent.parent
    return current_dir / "data" / "profiles"


def list_profiles() -> list[str]:
    profiles_dir = _get_profiles_dir()
    if not profiles_dir.exists():
        return []
    return sorted(p.stem for p in profiles_dir.glob("*.json"))


def load_profile(name: str) -> UserProfile:
    profiles_dir = _get_profiles_dir()
    path = profiles_dir / f"{name}.json"
    with open(path) as f:
        data = json.load(f)
    return UserProfile.model_validate(data)


def save_profile(profile: UserProfile) -> None:
    profiles_dir = _get_profiles_dir()
    profiles_dir.mkdir(parents=True, exist_ok=True)
    path = profiles_dir / f"{profile.name}.json"
    with open(path, "w") as f:
        f.write(profile.model_dump_json(indent=2))


def delete_profile(name: str) -> None:
    profiles_dir = _get_profiles_dir()
    path = profiles_dir / f"{name}.json"
    if path.exists():
        path.unlink()
